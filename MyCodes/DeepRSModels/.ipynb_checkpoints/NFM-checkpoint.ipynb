{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 动机\n",
    "\n",
    "NFM(Neural Factorization Machines)是2017年由新加坡国立大学的何向南教授等人在SIGIR会议上提出的一个模型，传统的FM模型仅局限于线性表达和二阶交互（**注解：本质还是特征交互深度不够**）， 无法胜任生活中各种具有复杂结构和规律性的真实数据， 针对FM的这点不足， 作者提出了一种将FM融合进DNN的策略，通过引进了一个特征交叉池化层的结构，使得FM与DNN进行了完美衔接，这样就**组合了FM的建模低阶特征交互能力和DNN学习高阶特征交互和非线性的能力**，形成了深度学习时代的神经FM模型(NFM)。\n",
    "\n",
    "那么NFM具体是怎么做的呢？ 首先看一下NFM的公式：\n",
    "$$\n",
    "\\hat{y}_{N F M}(\\mathbf{x})=w_{0}+\\sum_{i=1}^{n} w_{i} x_{i}+f(\\mathbf{x})\n",
    "$$\n",
    "我们对比FM， 就会发现变化的是第三项，前两项还是原来的， 因为我们说FM的一个问题，就是只能到二阶交叉， 且是线性模型， 这是他本身的一个局限性， 而如果想突破这个局限性， 就需要从他的公式本身下点功夫， 于是乎，作者在这里改进的思路就是**用一个表达能力更强的函数来替代原FM中二阶隐向量内积的部分**。\n",
    "\n",
    "<img src=\"http://ryluo.oss-cn-chengdu.aliyuncs.com/图片1.png\" style=\"zoom:70%;\" />\n",
    "\n",
    "而这个表达能力更强的函数呢， **我们很容易就可以想到神经网络来充当**，**因为神经网络理论上可以拟合任何复杂能力的函数**， 所以作者真的就把这个$f(x)$换成了一个神经网络，当然不是一个简单的DNN， 而是依然底层考虑了交叉，然后高层使用的DNN网络， 这个也就是我们最终的NFM网络了：\n",
    "\n",
    "<img src=\"http://ryluo.oss-cn-chengdu.aliyuncs.com/图片2.png\" style=\"zoom:80%;\" />\n",
    "\n",
    "这个结构，如果前面看过了PNN的伙伴会发现，这个结构和PNN非常像，只不过那里是一个product_layer， 而这里换成了Bi-Interaction Pooling了， 这个也是NFM的核心结构了。这里注意， 这个结构中，忽略了一阶部分，只可视化出来了$f(x)$， 我们还是下面从底层一点点的对这个网络进行剖析。\n",
    "（本质还是关注于特征交互，思路和创意进步。想到并且能落实也是挺牛逼的！）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型结构与原理\n",
    "\n",
    "### 2.1 Input 和Embedding层\n",
    "\n",
    "输入层的特征， 文章指定了稀疏离散特征居多， 这种特征我们也知道一般是先one-hot, 然后会通过embedding，处理成稠密低维的。 所以这两层还是和之前一样，假设$\\mathbf{v}_{\\mathbf{i}} \\in \\mathbb{R}^{k}$为第$i$个特征的embedding向量， 那么$\\mathcal{V}_{x}=\\left\\{x_{1} \\mathbf{v}_{1}, \\ldots, x_{n} \\mathbf{v}_{n}\\right\\}$表示的下一层的输入特征。这里带上了$x_i$是因为很多$x_i$转成了One-hot之后，出现很多为0的， 这里的$\\{x_iv_i\\}$是$x_i$不等于0的那些特征向量。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型结构与原理\n",
    "\n",
    "### 2.1 Input 和Embedding层\n",
    "\n",
    "输入层的特征， 文章指定了稀疏离散特征居多， 这种特征我们也知道一般是先one-hot, 然后会通过embedding，处理成稠密低维的。 所以这两层还是和之前一样，假设$\\mathbf{v}_{\\mathbf{i}} \\in \\mathbb{R}^{k}$为第$i$个特征的embedding向量， 那么$\\mathcal{V}_{x}=\\left\\{x_{1} \\mathbf{v}_{1}, \\ldots, x_{n} \\mathbf{v}_{n}\\right\\}$表示的下一层的输入特征。这里带上了$x_i$是因为很多$x_i$转成了One-hot之后，出现很多为0的， 这里的$\\{x_iv_i\\}$是$x_i$不等于0的那些特征向量。  \n",
    "\n",
    "### 2.2 Bi-Interaction Pooling layer\n",
    "\n",
    "在**Embedding层和神经网络之间加入了特征交叉池化层**是本网络的**核心创新**了，正是因为这个结构，实现了FM与DNN的无缝连接， 组成了一个大的网络，且能够正常的反向传播。假设$\\mathcal{V}_{x}$是所有特征embedding的集合， 那么在特征交叉池化层的操作：\n",
    "\n",
    "$$\n",
    "f_{B I}\\left(\\mathcal{V}_{x}\\right)=\\sum_{i=1}^{n} \\sum_{j=i+1}^{n} x_{i} \\mathbf{v}_{i} \\odot x_{j} \\mathbf{v}_{j}\n",
    "$$\n",
    "\n",
    "$\\odot$表示两个向量的元素积操作，即两个向量对应维度相乘得到的元素积向量（可不是点乘呀），其中第$k$维的操作：\n",
    "$$\n",
    "\\left(v_{i} \\odot v_{j}\\right)_{k}=\\boldsymbol{v}_{i k} \\boldsymbol{v}_{j k}\n",
    "$$\n",
    "\n",
    "这便定义了在embedding空间特征的二阶交互，这个不仔细看会和感觉FM的最后一项很像，但是不一样，一定要注意**这个地方不是两个隐向量的内积，而是元素积**，也就是这一个交叉完了之后k个维度不求和，最后会得到一个$k$维向量，而FM那里内积的话最后得到一个数， 在进行两两Embedding元素积之后，对交叉特征向量取和， 得到该层的输出向量， 很显然， **输出是一个$k$维的向量**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意， 之前的FM到这里其实就完事了， 上面就是输出了，而**这里很大的一点改进就是加入特征池化层之后， 把二阶交互的信息合并， 且上面接了一个DNN网络， 这样就能够增强FM的表达能力了**， 因为FM只能到二阶， 而这里的DNN可以进行多阶且非线性，只要FM把二阶的学习好了， DNN这块学习来会更加容易， 作者在论文中也说明了这一点，且通过后面的实验证实了这个观点。\n",
    "\n",
    "如果不加DNN， NFM就退化成了FM，所以改进的关键就在于加了一个这样的层，组合了一下二阶交叉的信息，然后又给了DNN进行高阶交叉的学习，成了一种“加强版”的FM。\n",
    "\n",
    "Bi-Interaction层不需要额外的模型学习参数，更重要的是它在一个线性的时间内完成计算，和FM一致的，即时间复杂度为$O\\left(k N_{x}\\right)$，$N_x$为embedding向量的数量。参考FM，可以将上式转化为：\n",
    "$$\n",
    "f_{B I}\\left(\\mathcal{V}_{x}\\right)=\\frac{1}{2}\\left[\\left(\\sum_{i=1}^{n} x_{i} \\mathbf{v}_{i}\\right)^{2}-\\sum_{i=1}^{n}\\left(x_{i} \\mathbf{v}_{i}\\right)^{2}\\right]\n",
    "$$\n",
    "后面代码复现NFM就是用的这个公式直接计算，比较简便且清晰。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 隐藏层\n",
    "\n",
    "这一层就是全连接的神经网络， **DNN在进行特征的高层非线性交互上有着天然的学习优势**，公式如下：\n",
    "$$\n",
    "\\begin{aligned} \n",
    "\\mathbf{z}_{1}=&\\sigma_{1}\\left(\\mathbf{W}_{1} f_{B I} \n",
    "\\left(\\mathcal{V}_{x}\\right)+\\mathbf{b}_{1}\\right)  \\\\\n",
    "\\mathbf{z}_{2}=& \\sigma_{2}\\left(\\mathbf{W}_{2} \\mathbf{z}_{1}+\\mathbf{b}_{2}\\right) \\\\\n",
    "\\ldots \\ldots \\\\\n",
    "\\mathbf{z}_{L}=& \\sigma_{L}\\left(\\mathbf{W}_{L} \\mathbf{z}_{L-1}+\\mathbf{b}_{L}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "这里的$\\sigma_i$是第$i$层的激活函数，可不要理解成sigmoid激活函数。\n",
    "\n",
    "(注：神经网络是基于感知机的扩展，而DNN可以理解为有很多隐藏层的神经网络。多层神经网络和深度神经网络DNN其实也是指的一个东西，DNN有时也叫做多层感知机（Multi-Layer perceptron,MLP）\n",
    "嗨，听了这么久DNN，原来就是MLP。。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 预测层\n",
    "\n",
    "这个就是最后一层的结果直接过一个隐藏层，但注意由于这里是回归问题，没有加sigmoid激活：\n",
    "$$\n",
    "f(\\mathbf{x})=\\mathbf{h}^{T} \\mathbf{z}_{L}\n",
    "$$\n",
    "\n",
    "所以， NFM模型的前向传播过程总结如下：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{y}_{N F M}(\\mathbf{x}) &=w_{0}+\\sum_{i=1}^{n} w_{i} x_{i} \\\\\n",
    "&+\\mathbf{h}^{T} \\sigma_{L}\\left(\\mathbf{W}_{L}\\left(\\ldots \\sigma_{1}\\left(\\mathbf{W}_{1} f_{B I}\\left(\\mathcal{V}_{x}\\right)+\\mathbf{b}_{1}\\right) \\ldots\\right)+\\mathbf{b}_{L}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "这就是NFM模型的全貌， NFM相比较于其他模型的核心创新点是特征交叉池化层，基于它，实现了FM和DNN的无缝连接，使得DNN可以在底层就学习到包含更多信息的组合特征，这时候，**就会减少DNN的很多负担，只需要很少的隐藏层就可以学习到高阶特征信息**。NFM相比之前的DNN， 模型结构更浅，更简单，但是性能更好，训练和调参更容易。集合FM二阶交叉线性和DNN高阶交叉非线性的优势，**非常适合处理稀疏数据的场景任务**。在对NFM的真实训练过程中，也会用到像Dropout和BatchNormalization这样的技术来**缓解过拟合**和**在过大的改变数据分布**。\n",
    "\n",
    "（**Mark:非常适合处理稀疏数据的场景任务**)\n",
    "\n",
    "下面通过代码看下NFM的具体实现过程， 学习一些细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 代码实现\n",
    "\n",
    "下面我们看下NFM的代码复现，这里主要是给大家说一下这个模型的设计逻辑，参考了deepctr的函数API的编程风格， 具体的代码以及示例大家可以去参考后面的GitHub，里面已经给出了详细的注释， 这里主要分析模型的逻辑这块。关于函数API的编程式风格，我们还给出了一份文档， 大家可以先看这个，再看后面的代码部分，会更加舒服些。下面开始：\n",
    "\n",
    "这里主要说一下NFM模型的总体运行逻辑， 这样可以让大家从宏观的层面去把握模型的设计过程， 该模型所使用的数据集是criteo数据集，具体介绍参考后面的GitHub。 数据集的特征会分为dense特征(连续,单词意思是稠密，但一般将数值特征作为dense特征)和sparse特征(离散，单词意思是稀疏，一般把分类特征作为sparse特征)， 所以模型的输入层接收这两种输入。但是我们这里把输入分成了linear input和dnn input两种情况，而每种情况都有可能包含上面这两种输入。因为我们后面的模型逻辑会分这两部分走，这里有个细节要注意，就是光看上面那个NFM模型的话，**是没有看到它线性特征处理的那部分的**，也就是FM的前半部分公式那里图里面是没有的。但是这里我们要加上。\n",
    "$$\n",
    "\\hat{y}_{N F M}(\\mathbf{x})=w_{0}+\\sum_{i=1}^{n} w_{i} x_{i}+f(\\mathbf{x})\n",
    "$$\n",
    "所以模型的逻辑我们分成了两大部分，这里我分别给大家解释下每一块做了什么事情：\n",
    "\n",
    "1. linear part: 这部分是有关于线性计算，也就是FM的前半部分$w1x1+w2x2...wnxn+b$的计算。对于这一块的计算，我们用了一个get_linear_logits函数实现，后面再说，总之通过这个函数，我们就可以实现上面这个公式的计算过程，得到linear的输出\n",
    "2. dnn part: 这部分是后面交叉特征的那部分计算，FM的最后那部分公式f(x)。 **这一块主要是针对离散的特征**，首先过embedding， 然后过特征交叉池化层，这个计算我们用了get_bi_interaction_pooling_output函数实现， 得到输出之后又过了DNN网络，最后得到dnn的输出\n",
    "\n",
    "模型的最后输出结果，就是把这两个部分的输出结果加和(当然也可以加权)，再过一个sigmoid得到。所以NFM的模型定义就出来了："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完整代码实现如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import  MinMaxScaler, LabelEncoder\n",
    "\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, VarLenSparseFeat\n",
    "# from utils import SparseFeat, DenseFeat, VarLenSparseFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单处理特征，包括填充缺失值，数值处理，类别编码\n",
    "def data_process(data_df, dense_features, sparse_features):\n",
    "    data_df[dense_features] = data_df[dense_features].fillna(0.0)\n",
    "    for f in dense_features:\n",
    "        data_df[f] = data_df[f].apply(lambda x: np.log(x+1) if x > -1 else -1)   # log 处理的用途是？  平滑？\n",
    "        \n",
    "    data_df[sparse_features] = data_df[sparse_features].fillna(\"-1\")\n",
    "    for f in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        data_df[f] = lbe.fit_transform(data_df[f])  # 编码离散特征\n",
    "    \n",
    "    return data_df[dense_features + sparse_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "和前几章节作用类似\n",
    "\"\"\"\n",
    "def build_input_layers(feature_columns):\n",
    "    # 构建Input层字典，并以dense和sparse两类字典的形式返回\n",
    "    dense_input_dict, sparse_input_dict = {}, {}\n",
    "\n",
    "    for fc in feature_columns:\n",
    "        if isinstance(fc, SparseFeat):\n",
    "            sparse_input_dict[fc.name] = Input(shape=(1, ), name=fc.name)\n",
    "        elif isinstance(fc, DenseFeat):\n",
    "            dense_input_dict[fc.name] = Input(shape=(fc.dimension, ), name=fc.name)\n",
    "        \n",
    "    return dense_input_dict, sparse_input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input_layers_dict 这个参数没有用上，是多余的么。。\n",
    "\"\"\"\n",
    "def build_embedding_layers(feature_columns, input_layers_dict, is_linear):\n",
    "    # 定义一个embedding层对应的字典\n",
    "    embedding_layers_dict = dict()\n",
    "    \n",
    "    # 将特征中的sparse特征筛选出来\n",
    "    sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if feature_columns else []  #预防空值\n",
    "    \n",
    "    # 如果是用于线性部分的embedding层，其维度为1，否则维度就是自己定义的embedding维度\n",
    "    # 线性一维的embedding，优于onehot,之前有提过\n",
    "    if is_linear:\n",
    "        for fc in sparse_feature_columns:\n",
    "            embedding_layers_dict[fc.name] = Embedding(fc.vocabulary_size, 1, name='1d_emb_' + fc.name)\n",
    "    else:\n",
    "        for fc in sparse_feature_columns:\n",
    "            embedding_layers_dict[fc.name] = Embedding(fc.vocabulary_size, fc.embedding_dim, name='kd_emb_' + fc.name)\n",
    "    \n",
    "    return embedding_layers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性处理部分\n",
    "def get_linear_logits(dense_input_dict, sparse_input_dict, sparse_feature_columns):\n",
    "    # 将所有的dense特征的Input层，然后经过一个全连接层得到dense特征的logits\n",
    "    concat_dense_inputs = Concatenate(axis=1)(list(dense_input_dict.values()))\n",
    "    dense_logits_output = Dense(1)(concat_dense_inputs)\n",
    "    \n",
    "    # 获取linear部分sparse特征的embedding层，这里使用embedding的原因是：\n",
    "    # 对于linear部分直接将特征进行onehot然后通过一个全连接层，当维度特别大的时候，计算比较慢\n",
    "    # 使用embedding层的好处就是可以通过查表的方式获取到哪些非零的元素对应的权重，然后在将这些权重相加，效率比较高\n",
    "    linear_embedding_layers = build_embedding_layers(sparse_feature_columns, sparse_input_dict, is_linear=True)\n",
    "    \n",
    "    # 将一维的embedding拼接，注意这里需要使用一个Flatten层，使维度对应\n",
    "    sparse_1d_embed = []\n",
    "    for fc in sparse_feature_columns:\n",
    "        feat_input = sparse_input_dict[fc.name]\n",
    "        embed = Flatten()(linear_embedding_layers[fc.name](feat_input))\n",
    "        sparse_1d_embed.append(embed)\n",
    "\n",
    "    # embedding中查询得到的权重就是对应onehot向量中一个位置的权重，所以后面不用再接一个全连接了，本身一维的embedding就相当于全连接\n",
    "    # 只不过是这里的输入特征只有0和1，所以直接向非零元素对应的权重相加就等同于进行了全连接操作(非零元素部分乘的是1)\n",
    "    sparse_logits_output = Add()(sparse_1d_embed)\n",
    "\n",
    "    # 最终将dense特征和sparse特征对应的logits相加，得到最终linear的logits。（稠密特征加上，线性部分中稀疏特征的Embedding)\n",
    "    linear_part = Add()([dense_logits_output, sparse_logits_output])\n",
    "    return linear_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本算法核心部分--之一\n",
    "class BiInteractionPooling(Layer):\n",
    "    def __init__(self):\n",
    "        super(BiInteractionPooling, self).__init__()\n",
    "\n",
    "    # 默认调用类方法\n",
    "    def call(self, inputs):\n",
    "        # 优化后的公式为： 0.5 * （和的平方-平方的和）  =>> B x k\n",
    "        concated_embeds_value = inputs # B x n x k\n",
    "\n",
    "        square_of_sum = tf.square(tf.reduce_sum(concated_embeds_value, axis=1, keepdims=False)) # B x k  和的平方\n",
    "        sum_of_square = tf.reduce_sum(concated_embeds_value * concated_embeds_value, axis=1, keepdims=False) # B x k  平方的和\n",
    "        cross_term = 0.5 * (square_of_sum - sum_of_square) # B x k\n",
    "\n",
    "        return cross_term\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, input_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "观察下 dnn_embedding_layers 这个参数，用的时候传入了什么？\n",
    "\"\"\"\n",
    "\n",
    "def get_bi_interaction_pooling_output(sparse_input_dict, sparse_feature_columns, dnn_embedding_layers):\n",
    "    # 只考虑sparse的二阶交叉，将所有的embedding拼接到一起\n",
    "    # 这里在实际运行的时候，其实只会将那些非零元素对应的embedding拼接到一起\n",
    "    # 并且将非零元素对应的embedding拼接到一起本质上相当于已经乘了x, 因为x中的值是1(公式中的x)\n",
    "    sparse_kd_embed = []\n",
    "    for fc in sparse_feature_columns:\n",
    "        feat_input = sparse_input_dict[fc.name]\n",
    "        _embed = dnn_embedding_layers[fc.name](feat_input) # B x 1 x k\n",
    "        sparse_kd_embed.append(_embed)\n",
    "\n",
    "    # 将所有sparse的embedding拼接起来，得到 (n, k)的矩阵，其中n为特征数，k为embedding大小\n",
    "    concat_sparse_kd_embed = Concatenate(axis=1)(sparse_kd_embed) # B x n x k\n",
    "    \n",
    "    pooling_out = BiInteractionPooling()(concat_sparse_kd_embed)   # 这里的内部逻辑不清楚。。将DNN部分，Embedding好的部分作为输入，\n",
    "                                                                    # 经过BiInteractionPooling处理后，再进DNN部分。\n",
    "    return pooling_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型dnn层\n",
    "def get_dnn_logits(pooling_out):\n",
    "    # dnn层，这里的Dropout参数，Dense中的参数都可以自己设定, 论文中还说使用了BN, 但是个人觉得BN和dropout同时使用\n",
    "    # 可能会出现一些问题，感兴趣的可以尝试一些，这里就先不加上了\n",
    "    #  BN 是什么。。\n",
    "    dnn_out = Dropout(0.5)(Dense(1024, activation='relu')(pooling_out))  \n",
    "    dnn_out = Dropout(0.3)(Dense(512, activation='relu')(dnn_out))\n",
    "    dnn_out = Dropout(0.1)(Dense(256, activation='relu')(dnn_out))\n",
    "\n",
    "    dnn_logits = Dense(1)(dnn_out)\n",
    "\n",
    "    return dnn_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总的模型\n",
    "def NFM(linear_feature_columns, dnn_feature_columns):\n",
    "    # 字典形式，构建输入层，是所有特征对应的Input()层\n",
    "    dense_input_dict, sparse_input_dict = build_input_layers(linear_feature_columns + dnn_feature_columns)\n",
    "    \n",
    "    # 将linear部分的特征中的，sparse 特征筛选出来，后面用来做1维的embedding\n",
    "    linear_sparse_feature_columns = list(filter(lambda x: isinstance(x,SparseFeat), linear_feature_columns))\n",
    "    \n",
    "    # 构建模型输入层， 应该是列表的形式，这里是与Input()层的对应\n",
    "    input_layers = list(dense_input_dict.values())  + list(sparse_input_dict.values())\n",
    "    \n",
    "    # linear_logits 一共有两部分：dense特征 和 sparse特征（这里是embedding之后的吗？）\n",
    "    linear_logits = get_linear_logits(dense_input_dict, sparse_input_dict, linear_sparse_feature_columns)  # get_linear_logits方法里面默认is_linear=True\n",
    "    \n",
    "    # 构建维度为 k 的embedding 层，这里使用字典的形式返回，方便后面搭建模型\n",
    "    # embedding 层用户构建FM交叉部分和 DNN的输入部分\n",
    "    embedding_layers = build_embedding_layers(dnn_feature_columns, sparse_input_dict, is_linear=False)\n",
    "    \n",
    "    # 将输入到 dnn 层的 sparse 特征筛选出来   # 这里有些不懂\n",
    "    dnn_sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeat), dnn_feature_columns))\n",
    "    pooling_output = get_bi_interaction_pooling_output(sparse_input_dict, dnn_sparse_feature_columns, embedding_layers) # B x (n(n-1)/2)\n",
    "    \n",
    "    # 论文中说到在池化之后加上了BN操作   # 所以BN是分布正则化么~\n",
    "    pooling_output = BatchNormalization()(pooling_output)\n",
    "    dnn_logits = get_dnn_logits(pooling_output)\n",
    "    \n",
    "    # 将linear,dnn的logits相加作为最终的logits\n",
    "    output_logits = Add()([linear_logits, dnn_logits])\n",
    "    \n",
    "    # 这里的激活函数使用sigmoid\n",
    "    output_layers = Activation(\"sigmoid\")(output_logits)\n",
    "    model = Model(input_layers, output_layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 总感觉有些没get到精髓。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "C1 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C2 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C3 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C4 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C5 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C6 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C7 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C8 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C9 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C10 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C11 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C12 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C13 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C14 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C15 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C16 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C17 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C18 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C19 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C20 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C21 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C22 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C23 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C24 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C25 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C26 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C1 (Embedding)           (None, 1, 4)         108         C1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C2 (Embedding)           (None, 1, 4)         368         C2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C3 (Embedding)           (None, 1, 4)         688         C3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C4 (Embedding)           (None, 1, 4)         628         C4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C5 (Embedding)           (None, 1, 4)         48          C5[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C6 (Embedding)           (None, 1, 4)         28          C6[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C7 (Embedding)           (None, 1, 4)         732         C7[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C8 (Embedding)           (None, 1, 4)         76          C8[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C9 (Embedding)           (None, 1, 4)         8           C9[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C10 (Embedding)          (None, 1, 4)         568         C10[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C11 (Embedding)          (None, 1, 4)         692         C11[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C12 (Embedding)          (None, 1, 4)         680         C12[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C13 (Embedding)          (None, 1, 4)         664         C13[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C14 (Embedding)          (None, 1, 4)         56          C14[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C15 (Embedding)          (None, 1, 4)         680         C15[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C16 (Embedding)          (None, 1, 4)         672         C16[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C17 (Embedding)          (None, 1, 4)         36          C17[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C18 (Embedding)          (None, 1, 4)         508         C18[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C19 (Embedding)          (None, 1, 4)         176         C19[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C20 (Embedding)          (None, 1, 4)         16          C20[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C21 (Embedding)          (None, 1, 4)         676         C21[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C22 (Embedding)          (None, 1, 4)         24          C22[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C23 (Embedding)          (None, 1, 4)         40          C23[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C24 (Embedding)          (None, 1, 4)         500         C24[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C25 (Embedding)          (None, 1, 4)         80          C25[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "kd_emb_C26 (Embedding)          (None, 1, 4)         360         C26[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 26, 4)        0           kd_emb_C1[0][0]                  \n",
      "                                                                 kd_emb_C2[0][0]                  \n",
      "                                                                 kd_emb_C3[0][0]                  \n",
      "                                                                 kd_emb_C4[0][0]                  \n",
      "                                                                 kd_emb_C5[0][0]                  \n",
      "                                                                 kd_emb_C6[0][0]                  \n",
      "                                                                 kd_emb_C7[0][0]                  \n",
      "                                                                 kd_emb_C8[0][0]                  \n",
      "                                                                 kd_emb_C9[0][0]                  \n",
      "                                                                 kd_emb_C10[0][0]                 \n",
      "                                                                 kd_emb_C11[0][0]                 \n",
      "                                                                 kd_emb_C12[0][0]                 \n",
      "                                                                 kd_emb_C13[0][0]                 \n",
      "                                                                 kd_emb_C14[0][0]                 \n",
      "                                                                 kd_emb_C15[0][0]                 \n",
      "                                                                 kd_emb_C16[0][0]                 \n",
      "                                                                 kd_emb_C17[0][0]                 \n",
      "                                                                 kd_emb_C18[0][0]                 \n",
      "                                                                 kd_emb_C19[0][0]                 \n",
      "                                                                 kd_emb_C20[0][0]                 \n",
      "                                                                 kd_emb_C21[0][0]                 \n",
      "                                                                 kd_emb_C22[0][0]                 \n",
      "                                                                 kd_emb_C23[0][0]                 \n",
      "                                                                 kd_emb_C24[0][0]                 \n",
      "                                                                 kd_emb_C25[0][0]                 \n",
      "                                                                 kd_emb_C26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bi_interaction_pooling (BiInter (None, 4)            0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 4)            16          bi_interaction_pooling[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         5120        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          524800      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "I1 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I2 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I3 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I4 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I5 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I6 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I7 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I8 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I9 (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I10 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I11 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I12 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "I13 (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C1 (Embedding)           (None, 1, 1)         27          C1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C2 (Embedding)           (None, 1, 1)         92          C2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C3 (Embedding)           (None, 1, 1)         172         C3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C4 (Embedding)           (None, 1, 1)         157         C4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C5 (Embedding)           (None, 1, 1)         12          C5[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C6 (Embedding)           (None, 1, 1)         7           C6[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C7 (Embedding)           (None, 1, 1)         183         C7[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C8 (Embedding)           (None, 1, 1)         19          C8[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C9 (Embedding)           (None, 1, 1)         2           C9[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C10 (Embedding)          (None, 1, 1)         142         C10[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C11 (Embedding)          (None, 1, 1)         173         C11[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C12 (Embedding)          (None, 1, 1)         170         C12[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C13 (Embedding)          (None, 1, 1)         166         C13[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C14 (Embedding)          (None, 1, 1)         14          C14[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C15 (Embedding)          (None, 1, 1)         170         C15[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C16 (Embedding)          (None, 1, 1)         168         C16[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C17 (Embedding)          (None, 1, 1)         9           C17[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C18 (Embedding)          (None, 1, 1)         127         C18[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C19 (Embedding)          (None, 1, 1)         44          C19[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C20 (Embedding)          (None, 1, 1)         4           C20[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C21 (Embedding)          (None, 1, 1)         169         C21[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C22 (Embedding)          (None, 1, 1)         6           C22[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C23 (Embedding)          (None, 1, 1)         10          C23[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C24 (Embedding)          (None, 1, 1)         125         C24[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C25 (Embedding)          (None, 1, 1)         20          C25[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "1d_emb_C26 (Embedding)          (None, 1, 1)         90          C26[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 13)           0           I1[0][0]                         \n",
      "                                                                 I2[0][0]                         \n",
      "                                                                 I3[0][0]                         \n",
      "                                                                 I4[0][0]                         \n",
      "                                                                 I5[0][0]                         \n",
      "                                                                 I6[0][0]                         \n",
      "                                                                 I7[0][0]                         \n",
      "                                                                 I8[0][0]                         \n",
      "                                                                 I9[0][0]                         \n",
      "                                                                 I10[0][0]                        \n",
      "                                                                 I11[0][0]                        \n",
      "                                                                 I12[0][0]                        \n",
      "                                                                 I13[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           1d_emb_C1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1)            0           1d_emb_C2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1)            0           1d_emb_C3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1)            0           1d_emb_C4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1)            0           1d_emb_C5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1)            0           1d_emb_C6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 1)            0           1d_emb_C7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 1)            0           1d_emb_C8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 1)            0           1d_emb_C9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 1)            0           1d_emb_C10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 1)            0           1d_emb_C11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 1)            0           1d_emb_C12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 1)            0           1d_emb_C13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 1)            0           1d_emb_C14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 1)            0           1d_emb_C15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 1)            0           1d_emb_C16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 1)            0           1d_emb_C17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 1)            0           1d_emb_C18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 1)            0           1d_emb_C19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 1)            0           1d_emb_C20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 1)            0           1d_emb_C21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 1)            0           1d_emb_C22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 1)            0           1d_emb_C23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 1)            0           1d_emb_C24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 1)            0           1d_emb_C25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 1)            0           1d_emb_C26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            14          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1)            0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "                                                                 flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "                                                                 flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1)            0           dense[0][0]                      \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            257         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1)            0           add_1[0][0]                      \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 672,925\n",
      "Trainable params: 672,917\n",
      "Non-trainable params: 8\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 2s 532ms/step - loss: 0.9842 - binary_crossentropy: 0.9842 - auc: 0.4763 - val_loss: 1.2991 - val_binary_crossentropy: 1.2991 - val_auc: 0.4516\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9027 - binary_crossentropy: 0.9027 - auc: 0.4926 - val_loss: 1.2630 - val_binary_crossentropy: 1.2630 - val_auc: 0.4473\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7958 - binary_crossentropy: 0.7958 - auc: 0.5233 - val_loss: 1.2169 - val_binary_crossentropy: 1.2169 - val_auc: 0.4487\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6462 - binary_crossentropy: 0.6462 - auc: 0.6266 - val_loss: 1.1805 - val_binary_crossentropy: 1.1805 - val_auc: 0.4544\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5348 - binary_crossentropy: 0.5348 - auc: 0.7592 - val_loss: 1.1736 - val_binary_crossentropy: 1.1736 - val_auc: 0.4516\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 读取数据\n",
    "    data = pd.read_csv('C:\\Users\\Administrator\\team-learning-rs\\DeepRecommendationModel\\代码\\data\\criteo_sample.txt')\n",
    "\n",
    "    # 划分dense和sparse特征\n",
    "    columns = data.columns.values\n",
    "    dense_features = [feat for feat in columns if 'I' in feat]\n",
    "    sparse_features = [feat for feat in columns if 'C' in feat]\n",
    "\n",
    "    # 简单的数据预处理\n",
    "    train_data = data_process(data, dense_features, sparse_features)\n",
    "    train_data['label'] = data['label']\n",
    "\n",
    "    # 将特征分组，分成linear部分和dnn部分(根据实际场景进行选择)，并将分组之后的特征做标记（使用DenseFeat, SparseFeat）\n",
    "    linear_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=4)\n",
    "                            for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
    "                            for feat in dense_features]\n",
    "\n",
    "    dnn_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=4)\n",
    "                            for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
    "                            for feat in dense_features]\n",
    "\n",
    "    # 构建NFM模型\n",
    "    history = NFM(linear_feature_columns, dnn_feature_columns)\n",
    "    history.summary()\n",
    "    history.compile(optimizer=\"adam\", \n",
    "                loss=\"binary_crossentropy\", \n",
    "                metrics=[\"binary_crossentropy\", tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "    # 将输入数据转化成字典的形式输入\n",
    "    train_model_input = {name: data[name] for name in dense_features + sparse_features}\n",
    "    # 模型训练\n",
    "    history.fit(train_model_input, train_data['label'].values,\n",
    "            batch_size=64, epochs=5, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**后面可以把Deepctr数据集下载下来预测下**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  有时间再好好研究下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了上面的解释，这个模型的宏观层面相信就很容易理解了。关于这每一块的细节，这里就不解释了，在我们给出的GitHub代码中，我们已经加了非常详细的注释，大家看那个应该很容易看明白， 为了方便大家的阅读，我们这里还给大家画了一个整体的模型架构图，帮助大家更好的了解每一块以及前向传播。（画的图不是很规范，先将就看一下，后面我们会统一在优化一下这个手工图）。\n",
    "\n",
    "<img src=\"http://ryluo.oss-cn-chengdu.aliyuncs.com/图片NFM_aaaa.png\" alt=\"NFM_aaaa\" style=\"zoom: 50%;\" />\n",
    "\n",
    "下面是一个通过keras画的模型结构图，为了更好的显示，数值特征和类别特征都只是选择了一小部分，画图的代码也在github中。\n",
    "\n",
    "![nfm](http://ryluo.oss-cn-chengdu.aliyuncs.com/图片nfm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 思考题\n",
    "\n",
    "1. NFM中的特征交叉与FM中的特征交叉有何异同，分别从原理和代码实现上进行对比分析\n",
    "\n",
    "##  回答：\n",
    "FM 特征交互只到了 2阶交互，然后就求和输出了\n",
    "但 NFM 这里的交互，是矩阵之间的交互，是一个表达能力更强的函数，形成元素积，也就是这一个交叉完了之后k个维度不求和，最后会得到一个 𝑘 维向量，而**FM那里内积的话最后得到一个数**， 在进行两两Embedding元素积之后，对交叉特征向量取和， 得到该层的输出向量， 很显然， **输出是一个 𝑘 维的向量**。ps；回顾了下学习内容，自知很不完善。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 参考资料\n",
    "\n",
    "- [论文原文](https://arxiv.org/pdf/1708.05027.pdf)\n",
    "\n",
    "- [deepctr](https://github.com/shenweichen/DeepCTR)\n",
    "\n",
    "- [AI上推荐 之 FNN、DeepFM与NFM(FM在深度学习中的身影重现)](https://blog.csdn.net/wuzhongqiang/article/details/109532267?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161442951716780255224635%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=161442951716780255224635&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v1~rank_blog_v1-1-109532267.pc_v1_rank_blog_v1&utm_term=NFM)\n",
    "\n",
    "- 王喆 - 《深度学习推荐系统》\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
