{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848436d1",
   "metadata": {},
   "source": [
    "# 排序模型\n",
    "\n",
    "通过召回的操作， 我们已经进行了问题规模的缩减， 对于每个用户， 选择出了N篇文章作为了候选集，并**基于召回的候选集构建了与用户历史相关的特征**，**以及用户本身的属性特征**，**文章本身的属性特征**，以及**用户与文章之间的特征**，下面就是使用机器学习模型来对构造好的特征进行学习，然后对测试集进行预测，得到测试集中的每个候选集用户点击的概率，**返回点击概率最大的topk个文章**，作为最终的结果。\n",
    "\n",
    "排序阶段选择了三个比较有代表性的排序模型，它们分别是：\n",
    "\n",
    "1. LGB的排序模型\n",
    "2. LGB的分类模型\n",
    "3. 深度学习的分类模型DIN\n",
    "\n",
    "得到了最终的排序模型输出的结果之后，还选择了两种比较经典的模型集成的方法：\n",
    "\n",
    "1. **输出结果加权融合**\n",
    "2. Staking（将模型的输出结果再**使用一个简单模型**进行预测）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7cbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc, os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9bd1e7",
   "metadata": {},
   "source": [
    "## 读取排序特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239b4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\Administrator\\RecommendSystem_Data\\RecommandNews_data\\data_raw\\\\'\n",
    "save_path = r'C:\\Users\\Administrator\\RecommendSystem_Data\\RecommandNews_data\\tmp_results\\\\'\n",
    "offline = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a2cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新读取数据的时候，发现click_article_id是一个浮点数，所以将其转换成int类型\n",
    "# 分别读取，训练，验证，测试数据\n",
    "trn_user_item_feats_df = pd.read_csv(save_path + 'trn_user_item_feats_df.csv')\n",
    "trn_user_item_feats_df['click_article_id'] = trn_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df = pd.read_csv(save_path + 'val_user_item_feats_df.csv')\n",
    "    val_user_item_feats_df['click_article_id'] = val_user_item_feats_df['click_article_id'].astype(int)\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "    \n",
    "tst_user_item_feats_df = pd.read_csv(save_path + 'tst_user_item_feats_df.csv')\n",
    "tst_user_item_feats_df['click_article_id'] = tst_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "# 做特征的时候为了方便，给测试集也打上了一个无效的标签，这里直接删掉就行\n",
    "del tst_user_item_feats_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa24236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed0d2d",
   "metadata": {},
   "source": [
    "### 返回排序后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd59934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(recall_df, topk=5, model_name=None):\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')  #同分不重复排名\n",
    "    \n",
    "    # 判断是不是每个用户都有5篇文章及以上\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    assert tmp.min() >= topk\n",
    "    \n",
    "    del recall_df['pred_score']\n",
    "    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    \"\"\"\n",
    "    注：这里要打开看一下\n",
    "    \"\"\"\n",
    "    \n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "    # 按照提交格式定义列名\n",
    "    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', \n",
    "                                                  3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    \n",
    "    save_name = save_path + model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n",
    "    submit.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bb91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序结果归一化\n",
    "def norm_sim(sim_df, weight=0.0):\n",
    "    # print(sim_df.head())\n",
    "    min_sim = sim_df.min()\n",
    "    max_sim = sim_df.max()\n",
    "    if max_sim == min_sim:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0)\n",
    "    else:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0 * (sim - min_sim) / (max_sim - min_sim))\n",
    "\n",
    "    sim_df = sim_df.apply(lambda sim: sim + weight)  # plus one\n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a0e771",
   "metadata": {},
   "source": [
    "### LGB排序模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c36e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 防止中间出错之后重新读取数据\n",
    "trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model = val_user_item_feats_df.copy()\n",
    "    \n",
    "tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "546a7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义特征列\n",
    "lgb_cols = ['sim0', 'time_diff0', 'word_diff0','sim_max', 'sim_min', 'sim_sum', \n",
    "            'sim_mean', 'score','click_size', 'time_diff_mean', 'active_level',\n",
    "            'click_environment','click_deviceGroup', 'click_os', 'click_country', \n",
    "            'click_region','click_referrer_type', 'user_time_hob1', 'user_time_hob2',\n",
    "            'words_hbo', 'category_id', 'created_at_ts','words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63bb4b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.548877</td>\n",
       "      <td>-0.429742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.666732</td>\n",
       "      <td>-1.692905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685470</td>\n",
       "      <td>0.316658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011107</td>\n",
       "      <td>-0.202242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.690449</td>\n",
       "      <td>-1.233406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.992060</td>\n",
       "      <td>-0.240974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>1.152560</td>\n",
       "      <td>-0.348993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>0.702055</td>\n",
       "      <td>0.855363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    key1  key2     data1     data2\n",
       "0 0    a     1 -0.548877 -0.429742\n",
       "  6    a     1 -0.666732 -1.692905\n",
       "1 1    a     2  0.685470  0.316658\n",
       "  2    a     2  0.011107 -0.202242\n",
       "2 3    b     1  0.690449 -1.233406\n",
       "  5    b     1 -0.992060 -0.240974\n",
       "3 4    b     2  1.152560 -0.348993\n",
       "  9    b     2  0.702055  0.855363"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'key1':list('aaabbbaabb'),\n",
    "\t\t\t\t'key2':[1,2,2,1,2,1,1,2,1,2,],\n",
    "\t\t\t\t'data1':np.random.randn(10),\n",
    "\t\t\t\t'data2':np.random.randn(10)})\n",
    "b1 = df.groupby(['key1','key2'],as_index=False).apply(lambda x:x.iloc[[0,1]])\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5233112b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(0, 0),\n",
       "            (0, 6),\n",
       "            (1, 1),\n",
       "            (1, 2),\n",
       "            (2, 3),\n",
       "            (2, 5),\n",
       "            (3, 4),\n",
       "            (3, 9)],\n",
       "           )"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "225e0024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">a</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.548877</td>\n",
       "      <td>-0.429742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.666732</td>\n",
       "      <td>-1.692905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685470</td>\n",
       "      <td>0.316658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011107</td>\n",
       "      <td>-0.202242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">b</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.690449</td>\n",
       "      <td>-1.233406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.992060</td>\n",
       "      <td>-0.240974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>1.152560</td>\n",
       "      <td>-0.348993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>0.702055</td>\n",
       "      <td>0.855363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key1  key2     data1     data2\n",
       "key1 key2                                 \n",
       "a    1    0    a     1 -0.548877 -0.429742\n",
       "          6    a     1 -0.666732 -1.692905\n",
       "     2    1    a     2  0.685470  0.316658\n",
       "          2    a     2  0.011107 -0.202242\n",
       "b    1    3    b     1  0.690449 -1.233406\n",
       "          5    b     1 -0.992060 -0.240974\n",
       "     2    4    b     2  1.152560 -0.348993\n",
       "          9    b     2  0.702055  0.855363"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = df.groupby(['key1','key2'],as_index=True).apply(lambda x:x.iloc[[0,1]])\n",
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f51245c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('a', 1, 0),\n",
       "            ('a', 1, 6),\n",
       "            ('a', 2, 1),\n",
       "            ('a', 2, 2),\n",
       "            ('b', 1, 3),\n",
       "            ('b', 1, 5),\n",
       "            ('b', 2, 4),\n",
       "            ('b', 2, 9)],\n",
       "           names=['key1', 'key2', None])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06f523e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.548877</td>\n",
       "      <td>-0.429742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685470</td>\n",
       "      <td>0.316658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.690449</td>\n",
       "      <td>-1.233406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>1.152560</td>\n",
       "      <td>-0.348993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    key1  key2     data1     data2\n",
       "0 0    a     1 -0.548877 -0.429742\n",
       "  1    a     2  0.685470  0.316658\n",
       "1 3    b     1  0.690449 -1.233406\n",
       "  4    b     2  1.152560 -0.348993"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b3 = df.groupby(['key1'],as_index=False).apply(lambda x:x.iloc[[0,1]])\n",
    "b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0da78ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b3.count()['key1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36205aa5",
   "metadata": {},
   "source": [
    "**注：ax_index=False 可以禁用分组键作为索引的行为，同时自动给定一个索引。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0744a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序模型分组\n",
    "trn_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "g_train = trn_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = val_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e35b6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序模型定义\n",
    "\"\"\"\n",
    "注：这里的参数是初始选择没有调参的。\n",
    "\"\"\"\n",
    "lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07bf414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_ranker.fit??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54582ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序模型训练\n",
    "\"\"\"\n",
    "eval_metric: Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
    "eval_at : iterable of int, optional (default=(1, 2, 3, 4, 5))  The evaluation positions of the specified metric.\n",
    "\"\"\"\n",
    "\n",
    "if offline:\n",
    "    lgb_ranker.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'], group=g_train,\n",
    "                eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model['label'])], \n",
    "                eval_group= [g_val], eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50, )\n",
    "else:\n",
    "    lgb_ranker.fit(trn_user_item_feats_df[lgb_cols], trn_user_item_feats_df['label'], group=g_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e0350fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "tst_user_item_feats_df['pred_score'] = lgb_ranker.predict(tst_user_item_feats_df[lgb_cols], num_iteration=lgb_ranker.best_iteration_)\n",
    "# num_iteration 选择表现最好的参数迭代\n",
    "\n",
    "# 将这里的排序结果保存一份，用户后面的模型融合\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'lgb_ranker_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7138ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_ranker')   # 调用 submit 方法，在本地生成提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58965923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_train : [1 1 1 ... 1 3 1]\n",
      "g_val : [1 1 1 ... 1 1 1]\n",
      "[1]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[3]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[4]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[5]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[6]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[7]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[8]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[9]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[10]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[11]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[12]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[13]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[14]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[15]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[16]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[17]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[18]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[19]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[20]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[21]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[22]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[23]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[24]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[25]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[26]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[27]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[28]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[29]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[30]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[31]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[32]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[33]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[34]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[35]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[36]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[37]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[38]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[39]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[40]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[41]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[42]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[43]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[44]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[45]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[46]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[47]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[48]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[49]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[50]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "[51]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.99975\tvalid_0's ndcg@2: 0.999908\tvalid_0's ndcg@3: 0.999908\tvalid_0's ndcg@4: 0.999908\tvalid_0's ndcg@5: 0.999908\n",
      "++++++++++++++++++++++++\n",
      "g_train : [1 1 1 ... 1 3 1]\n",
      "g_val : [1 1 1 ... 1 1 1]\n",
      "[1]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[3]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[4]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[5]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[6]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[7]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[9]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[10]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[11]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[12]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[13]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[14]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[15]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[16]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[17]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[18]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[19]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[20]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[21]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[22]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[23]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[24]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[25]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[26]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[27]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[28]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[29]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[30]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[31]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[32]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[33]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[34]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[35]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[36]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[37]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[38]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[39]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[40]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[41]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[42]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[43]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[44]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[45]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[46]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[47]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[48]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[49]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[50]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "[51]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.999775\tvalid_0's ndcg@2: 0.999917\tvalid_0's ndcg@3: 0.999917\tvalid_0's ndcg@4: 0.999917\tvalid_0's ndcg@5: 0.999917\n",
      "++++++++++++++++++++++++\n",
      "g_train : [1 1 1 ... 1 3 1]\n",
      "g_val : [1 1 1 ... 1 1 1]\n",
      "[1]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[3]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[4]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[5]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[6]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[7]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[8]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[9]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[10]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[11]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[12]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[13]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[14]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[15]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[16]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[17]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[18]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[19]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[20]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[21]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[22]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[23]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[25]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[26]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[27]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[28]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[29]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[30]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[31]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[32]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[33]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[34]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[35]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[36]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[37]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[38]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[39]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[40]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[41]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[42]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[43]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[44]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[45]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[46]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[47]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[48]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[49]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[50]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "[51]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.999725\tvalid_0's ndcg@2: 0.999899\tvalid_0's ndcg@3: 0.999899\tvalid_0's ndcg@4: 0.999899\tvalid_0's ndcg@5: 0.999899\n",
      "++++++++++++++++++++++++\n",
      "g_train : [1 1 1 ... 1 1 1]\n",
      "g_val : [1 1 1 ... 1 1 3]\n",
      "[1]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[3]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[4]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[5]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[6]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[7]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[8]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[9]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[10]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[11]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[12]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[13]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[14]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[15]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[16]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[17]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[18]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[19]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[20]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[21]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[22]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[23]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[24]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[25]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[26]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[27]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[28]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[29]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[30]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[31]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[32]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[33]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[34]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[36]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[37]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[38]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[39]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[40]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[41]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[42]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[43]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[44]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[45]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[46]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[47]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[48]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[49]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[50]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "[51]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.999875\tvalid_0's ndcg@2: 0.999954\tvalid_0's ndcg@3: 0.999954\tvalid_0's ndcg@4: 0.999954\tvalid_0's ndcg@5: 0.999954\n",
      "++++++++++++++++++++++++\n",
      "g_train : [1 1 1 ... 1 1 3]\n",
      "g_val : [1 1 1 ... 1 1 1]\n",
      "[1]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[3]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[4]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[5]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[6]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[7]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[8]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[9]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[10]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[11]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[12]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[13]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[14]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[15]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[16]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[17]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[18]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[19]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[20]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[21]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[22]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[23]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[24]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[25]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[26]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[27]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[28]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[29]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[30]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[31]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[32]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[33]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[34]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[35]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[36]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[37]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[38]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[39]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[40]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[41]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[42]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[44]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[45]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[46]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[47]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[48]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[49]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[50]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "[51]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.99965\tvalid_0's ndcg@2: 0.999871\tvalid_0's ndcg@3: 0.999871\tvalid_0's ndcg@4: 0.999871\tvalid_0's ndcg@5: 0.999871\n",
      "++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]   # 这个取 5 折的方法很好\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id','label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user   # 选出不在 5 折中的其他用户，作为训练用户\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 训练集与验证集的用户分组\n",
    "    train_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_train = train_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    print(\"g_train :\" , g_train)  # g_train : [1 1 1 ... 1 1 3]  是这样的形式\n",
    "\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = valid_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    print(\"g_val :\" , g_val)  # g_val : [1 1 1 ... 1 1 1]  是这样的形式\n",
    "    \n",
    "    # 定义模型\n",
    "    lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16)  \n",
    "    # 训练模型\n",
    "    lgb_ranker.fit(train_idx[lgb_cols], train_idx['label'], group=g_train,\n",
    "                   eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], eval_group= [g_val], \n",
    "                   eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_ranker.predict(valid_idx[lgb_cols], num_iteration=lgb_ranker.best_iteration_)\n",
    "    \n",
    "    # 对输出结果进行归一化\n",
    "    valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        print(\"++++++++++++++++++++++++\")\n",
    "        sub_preds += lgb_ranker.predict(tst_user_item_feats_df_rank_model[lgb_cols], lgb_ranker.best_iteration_)\n",
    "        \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])  # 这里是为什么？\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_ranker_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))  # norm_sim 把0全都转为1了\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_ranker_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2e2dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "# 单模型生成提交结果\n",
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_ranker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b652c8",
   "metadata": {},
   "source": [
    "### LGB分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b39f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型及参数的定义\n",
    "lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=500, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90f352c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 89, number of negative: 206488\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042934\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000016 seconds, init for row-wise cost 0.027695 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4113\n",
      "[LightGBM] [Info] Number of data points in the train set: 206577, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000431 -> initscore=-7.749361\n",
      "[LightGBM] [Info] Start training from score -7.749361\n",
      "[LightGBM] [Debug] Re-bagging, using 144808 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144418 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144355 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144474 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144881 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144541 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144760 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144704 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144603 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144375 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144677 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144834 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144844 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144437 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144970 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144741 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144770 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144577 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144709 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144258 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144662 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144377 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 145257 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144705 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144917 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144617 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144285 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144402 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144647 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144514 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144363 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144608 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144260 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144715 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144643 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144620 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144311 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144677 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144505 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 145139 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144693 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144710 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144527 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144908 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144557 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144519 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144190 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144744 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144631 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144391 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144262 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144852 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144433 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144739 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144455 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144706 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144906 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144455 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144968 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144439 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144573 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144670 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144704 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144388 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144555 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144519 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144707 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144407 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144500 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144239 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144370 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144526 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144423 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144381 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144633 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144603 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144531 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144282 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144522 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144979 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144512 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144582 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144565 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144563 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144446 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144741 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144521 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144075 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144820 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144796 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144845 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144550 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144712 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144548 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144693 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144532 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144209 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144389 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144308 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144466 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144732 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144546 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144644 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144466 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144744 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144612 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144440 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144699 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144553 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144625 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144577 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144647 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144116 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144564 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144632 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144924 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144557 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144785 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144731 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144554 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144625 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144575 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144556 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144371 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144695 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144446 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144763 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144615 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144652 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144566 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144327 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144625 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144347 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144826 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144494 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144434 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144977 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144754 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144670 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144632 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144583 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144792 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144725 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144697 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144668 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 144697 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144804 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144692 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144648 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144754 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144668 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144438 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144830 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144615 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144015 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144516 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144427 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144668 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144450 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144851 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144555 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144936 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144500 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144464 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144761 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144604 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144671 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144817 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144388 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144642 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144847 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144494 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144713 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144371 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144946 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144595 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144424 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144645 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144590 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 144665 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144619 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144421 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144238 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144547 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144805 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144724 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144692 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144810 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144743 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144359 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144758 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144714 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144480 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144782 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144780 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144603 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144673 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144488 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144404 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144959 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144483 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144389 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144575 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144818 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144571 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144840 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144595 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144584 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144474 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144580 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144606 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144506 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144376 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 144698 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144341 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144411 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144941 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144910 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144667 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144177 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144843 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144448 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144709 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144426 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144599 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144726 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144315 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 145023 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144867 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144885 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144285 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144769 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144922 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144649 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144402 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144522 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144571 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144664 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144497 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144340 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144435 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144629 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144516 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144443 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 144936 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144376 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144544 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144708 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144889 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144966 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144942 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 145089 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144818 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144600 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 145206 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144838 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144421 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144157 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144766 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144422 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144795 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144251 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144601 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144921 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144778 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144519 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144634 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144717 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144374 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144362 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144453 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144569 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144746 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144297 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144606 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144776 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144752 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144816 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144392 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144717 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144686 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144486 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144595 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144885 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144855 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144413 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144346 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144756 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144426 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144204 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144397 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144271 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144821 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144820 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144742 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144693 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144299 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144332 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144901 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144463 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144678 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144724 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144666 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144595 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144889 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144729 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144771 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144940 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144666 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144811 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144779 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144309 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144407 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144861 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144566 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144747 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144736 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144540 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144682 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144682 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144808 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144828 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144778 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144490 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144623 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 145055 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144431 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144225 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144448 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144599 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144602 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144320 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144536 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144805 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144197 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144752 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144466 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144842 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144680 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144826 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144696 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144403 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144718 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144529 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144977 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144479 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144856 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144311 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144696 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144338 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144665 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144473 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144650 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144272 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144880 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144817 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144662 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144405 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144892 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144648 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144459 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144737 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144788 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144460 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144845 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144675 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144501 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 145050 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144626 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144418 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144436 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144689 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144565 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144345 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144754 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144229 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144376 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144699 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144488 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144379 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144806 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144761 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144695 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144463 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144713 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144454 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144852 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144633 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144689 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144743 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144853 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144549 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144501 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144297 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144635 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144841 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144817 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144552 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144847 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144655 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144487 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144522 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144726 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144557 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144522 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 145009 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144752 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144600 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144898 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144723 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144498 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144638 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144709 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144529 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144384 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144757 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144849 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144786 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144295 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144686 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144569 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144457 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144266 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144497 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144564 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144590 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144276 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144037 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144843 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144424 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144717 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144625 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144514 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144317 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144583 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144336 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144567 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144610 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144449 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144356 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144778 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144655 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144382 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144827 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144301 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144578 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144694 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144818 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144533 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144719 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144297 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144665 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144382 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144632 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 145043 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144382 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144555 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144786 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144605 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144674 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144548 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144768 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144800 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144299 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144646 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144618 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144788 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144235 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144177 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144620 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144125 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144298 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144548 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 145130 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144396 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144592 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144478 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144717 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144475 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144473 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144764 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144663 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144140 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144671 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144680 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144356 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144705 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144532 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144502 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144726 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144297 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144989 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144253 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144388 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144474 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144486 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 144699 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "if offline:\n",
    "    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'],\n",
    "                    eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model['label'])], \n",
    "                    eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "else:\n",
    "    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a940df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "tst_user_item_feats_df['pred_score'] = lgb_Classfication.predict_proba(tst_user_item_feats_df[lgb_cols])[:,1]\n",
    "\n",
    "# 将这里的排序结果保存一份，用户后面的模型融合\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'lgb_cls_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f5a470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f884b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 71, number of negative: 165222\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042924\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000015 seconds, init for row-wise cost 0.019101 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4106\n",
      "[LightGBM] [Info] Number of data points in the train set: 165293, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000430 -> initscore=-7.752365\n",
      "[LightGBM] [Info] Start training from score -7.752365\n",
      "[LightGBM] [Debug] Re-bagging, using 115698 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 115670 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115307 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115539 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115655 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115886 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115630 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115902 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115733 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115709 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115345 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115807 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115869 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 116015 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115572 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 116083 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115852 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115822 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115638 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115835 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115439 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115813 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115537 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 116226 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115800 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 116085 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115630 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115285 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115673 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115776 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115525 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115810 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115666 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115323 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115910 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115638 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115498 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115511 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115829 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115723 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 116036 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115907 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115716 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115708 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115813 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115720 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115689 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115405 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115898 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115641 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Debug] Re-bagging, using 115542 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00676031\n",
      "[LightGBM] [Info] Number of positive: 69, number of negative: 165232\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042947\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000016 seconds, init for row-wise cost 0.022085 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4103\n",
      "[LightGBM] [Info] Number of data points in the train set: 165301, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000417 -> initscore=-7.780999\n",
      "[LightGBM] [Info] Start training from score -7.780999\n",
      "[LightGBM] [Debug] Re-bagging, using 115703 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 115673 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115318 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115544 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115658 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115895 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115637 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115896 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115748 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115717 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115340 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115818 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115872 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 116023 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115587 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 116083 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115862 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115832 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115642 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115830 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115445 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115822 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115547 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 116211 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115826 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 116069 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115650 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115290 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115669 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115789 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115529 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115816 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115670 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115333 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115913 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115631 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115524 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115499 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115838 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115740 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 116039 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115913 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115712 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115730 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115800 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115744 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115688 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115418 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115903 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115645 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Debug] Re-bagging, using 115548 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00754063\n",
      "[LightGBM] [Info] Number of positive: 74, number of negative: 165233\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042938\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000016 seconds, init for row-wise cost 0.024193 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4105\n",
      "[LightGBM] [Info] Number of data points in the train set: 165307, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000448 -> initscore=-7.711047\n",
      "[LightGBM] [Info] Start training from score -7.711047\n",
      "[LightGBM] [Debug] Re-bagging, using 115709 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 115676 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115324 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115545 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 115660 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115904 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115639 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115899 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115750 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115709 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115364 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115813 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115884 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 116020 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115593 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 116090 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115864 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115838 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115645 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115831 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115456 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115820 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115547 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 116218 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115838 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 116065 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115658 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115290 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115690 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 115782 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115535 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115807 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115680 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115350 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115916 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115644 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115512 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115485 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115870 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115734 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 116056 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115899 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115735 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115718 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115820 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115740 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115688 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115437 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115899 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115647 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Debug] Re-bagging, using 115553 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00560552\n",
      "[LightGBM] [Info] Number of positive: 78, number of negative: 165183\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042938\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000134 seconds, init for row-wise cost 0.027925 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4102\n",
      "[LightGBM] [Info] Number of data points in the train set: 165261, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000472 -> initscore=-7.658100\n",
      "[LightGBM] [Info] Start training from score -7.658100\n",
      "[LightGBM] [Debug] Re-bagging, using 115678 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 115642 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115282 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115525 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115633 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115863 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115606 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115875 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115722 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115690 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115332 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115764 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115859 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115991 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115554 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 116056 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115824 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115791 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115606 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115822 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115434 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115794 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115502 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 116201 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115781 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 116057 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115619 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115277 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115641 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115746 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115503 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 115779 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115660 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115305 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115877 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115606 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115474 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115488 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115832 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115694 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 116022 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115866 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115679 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115701 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115775 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115708 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115651 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115392 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115864 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115616 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Debug] Re-bagging, using 115516 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00407802\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 165082\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042943\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000018 seconds, init for row-wise cost 0.021027 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4101\n",
      "[LightGBM] [Info] Number of data points in the train set: 165146, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000388 -> initscore=-7.855315\n",
      "[LightGBM] [Info] Start training from score -7.855315\n",
      "[LightGBM] [Debug] Re-bagging, using 115596 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 115555 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 115207 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115448 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115553 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115787 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115532 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115784 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115646 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115615 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115267 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115707 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115762 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115918 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115475 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115969 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115740 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115719 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115508 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115720 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115339 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115707 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115429 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 116126 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115705 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115972 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115557 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115197 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115580 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115676 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115428 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115695 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115579 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115229 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115797 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115539 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115397 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115392 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115754 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115622 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115923 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115798 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115606 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115609 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115687 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115628 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115581 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115300 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115782 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115528 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "[LightGBM] [Debug] Re-bagging, using 115421 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00948015\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id', 'label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 模型及参数的定义\n",
    "    lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)  \n",
    "    # 训练模型\n",
    "    lgb_Classfication.fit(train_idx[lgb_cols], train_idx['label'],eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], \n",
    "                          eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_Classfication.predict_proba(valid_idx[lgb_cols], \n",
    "                                                              num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "    # 对输出结果进行归一化 分类模型输出的值本身就是一个概率值不需要进行归一化\n",
    "    # valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_Classfication.predict_proba(tst_user_item_feats_df_rank_model[lgb_cols], \n",
    "                                                     num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_cls_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_cls_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1353d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e1c89",
   "metadata": {},
   "source": [
    "## DIN模型\n",
    "\n",
    "### 用户的历史点击行为列表\n",
    "\n",
    "这个是为后面的DIN模型服务的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63d2ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if offline:\n",
    "    all_data = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "else:\n",
    "    trn_data = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    tst_data = pd.read_csv(data_path + 'testA_click_log.csv')\n",
    "    all_data = trn_data.append(tst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02d29e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_click =all_data[['user_id', 'click_article_id']].groupby('user_id').agg({list}).reset_index()\n",
    "his_behavior_df = pd.DataFrame()\n",
    "his_behavior_df['user_id'] = hist_click['user_id']\n",
    "his_behavior_df['hist_click_article_id'] = hist_click['click_article_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70b410db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>user_time_hob1</th>\n",
       "      <th>user_time_hob2</th>\n",
       "      <th>words_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16800</td>\n",
       "      <td>0.238681</td>\n",
       "      <td>260897000</td>\n",
       "      <td>48</td>\n",
       "      <td>0.238681</td>\n",
       "      <td>0.238681</td>\n",
       "      <td>0.238681</td>\n",
       "      <td>0.238681</td>\n",
       "      <td>-108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1508445988000</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  click_article_id      sim0  time_diff0  word_diff0   sim_max  \\\n",
       "0        0             16800  0.238681   260897000          48  0.238681   \n",
       "\n",
       "    sim_min   sim_sum  sim_mean  score  ...  click_country  click_region  \\\n",
       "0  0.238681  0.238681  0.238681 -108.0  ...              1            25   \n",
       "\n",
       "   click_referrer_type  user_time_hob1  user_time_hob2  words_hbo  \\\n",
       "0                    2        0.343715        0.992865      266.0   \n",
       "\n",
       "   category_id  created_at_ts  words_count  is_cat_hab  \n",
       "0            7  1508445988000          210           0  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7328760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_user_item_feats_df_din_model = trn_user_item_feats_df.copy()\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_din_model = val_user_item_feats_df.copy()\n",
    "else: \n",
    "    val_user_item_feats_df_din_model = None\n",
    "    \n",
    "tst_user_item_feats_df_din_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23e81a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_user_item_feats_df_din_model = trn_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_din_model = val_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')\n",
    "else:\n",
    "    val_user_item_feats_df_din_model = None\n",
    "\n",
    "tst_user_item_feats_df_din_model = tst_user_item_feats_df_din_model.merge(his_behavior_df, on='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22860072",
   "metadata": {},
   "source": [
    "### DIN模型简介\n",
    "\n",
    "我们下面尝试使用DIN模型， DIN的全称是Deep Interest Network， 这是阿里2018年基于前面的深度学习模型无法表达用户多样化的兴趣而提出的一个模型， **它可以通过考虑【给定的候选广告】和【用户的历史行为】的相关性，来计算用户兴趣的表示向量**。具体来说就是**通过引入局部激活单元，通过软搜索历史行为的相关部分来关注相关的用户兴趣，并采用加权和来获得有关候选广告的用户兴趣的表示**。**与候选广告相关性较高的行为会获得较高的激活权重，并支配着用户兴趣**。该表示向量在不同广告上有所不同，大大提高了模型的表达能力。所以该模型对于此次新闻推荐的任务也比较适合， 我们在这里通过当前的候选文章与用户历史点击文章的相关性来计算用户对于文章的兴趣。 该模型的结构如下：\n",
    "\n",
    "![image-20201116201646983](http://ryluo.oss-cn-chengdu.aliyuncs.com/abc/image-20201116201646983.png)\n",
    "\n",
    "\n",
    "我们这里直接调包来使用这个模型， 关于这个模型的详细细节部分我们会在下一期的推荐系统组队学习中给出。下面说一下该模型如何具体使用：deepctr的函数原型如下：\n",
    "\n",
    "> def DIN(dnn_feature_columns, history_feature_list, dnn_use_bn=False,\n",
    ">     dnn_hidden_units=(200, 80), dnn_activation='relu', att_hidden_size=(80, 40), att_activation=\"dice\",\n",
    ">    att_weight_normalization=False, l2_reg_dnn=0, l2_reg_embedding=1e-6, dnn_dropout=0, seed=1024,\n",
    ">     task='binary'):\n",
    ">\n",
    "> * dnn_feature_columns: 特征列， 包含数据所有特征的列表\n",
    "> * history_feature_list: 用户历史行为列， 反应用户历史行为的特征的列表\n",
    "> * dnn_use_bn: 是否使用BatchNormalization\n",
    "> * dnn_hidden_units: 全连接层网络的层数和每一层神经元的个数， 一个列表或者元组\n",
    "> * dnn_activation_relu: 全连接网络的激活单元类型\n",
    "> * att_hidden_size: 注意力层的全连接网络的层数和每一层神经元的个数\n",
    "> * att_activation: 注意力层的激活单元类型\n",
    "> * att_weight_normalization: 是否归一化注意力得分\n",
    "> * l2_reg_dnn: 全连接网络的正则化系数\n",
    "> * l2_reg_embedding: embedding向量的正则化稀疏\n",
    "> * dnn_dropout: 全连接网络的神经元的失活概率\n",
    "> * task: 任务， 可以是分类， 也可是是回归\n",
    "\n",
    "在具体使用的时候， 我们必须要传入特征列和历史行为列， 但是再传入之前， 我们需要进行一下特征列的预处理。具体如下：\n",
    "\n",
    "1. 首先，我们要处理数据集， 得到数据， 由于我们是基于用户过去的行为去预测用户是否点击当前文章， 所以**我们需要把数据的特征列划分成数值型特征， 离散型特征和历史行为特征列三部分**， 对于每一部分， DIN模型的处理会有不同\n",
    "   1. 对于离散型特征， 在我们的数据集中就是那些类别型的特征， 比如user_id这种， 这种类别型特征， 我们**首先要经过embedding处理得到每个特征的低维稠密型表示**， 既然要经过embedding， 那么我们就需要为每一列的类别特征的取值建立一个字典，并指明embedding维度， 所以在使用deepctr的DIN模型准备数据的时候， **我们需要通过SparseFeat函数指明这些类别型特征, 这个函数的传入参数就是列名， 列的唯一取值(建立字典用)和embedding维度**。\n",
    "   2. 对于用户历史行为特征列， 比如文章id， 文章的类别等这种， 同样的我们需要先经过embedding处理， 只不过和上面不一样的地方是，对于这种特征， 我们在得到每个特征的embedding表示之后， 还需要通过一个Attention_layer**计算用户的历史行为**和**当前候选文章的相关性**以此得到当前用户的embedding向量， 这个向量就可以**基于当前的候选文章**与**用户过去点击过得历史文章的相似性**的程度来反应用户的兴趣， 并且随着用户的不同的历史点击来变化，去动态的模拟用户兴趣的变化过程。这类特征对于每个用户都是一个历史行为序列， 对于每个用户， 历史行为序列长度会不一样， 可能有的用户点击的历史文章多，有的点击的历史文章少， **所以我们还需要把这个长度统一起来**， 在为DIN模型准备数据的时候， 我们首先要通过SparseFeat函数指明这些类别型特征， 然后还需要通过VarLenSparseFeat函数再进行序列填充， 使得每个用户的历史序列一样长， 所以这个函数参数中会有个maxlen，来指明序列的最大长度是多少。\n",
    "   3. **对于连续型特征列， 我们只需要用DenseFeat函数来指明列名和维度即可**。\n",
    "2. 处理完特征列之后， 我们把相应的数据与列进行对应，就得到了最后的数据。\n",
    "\n",
    "下面根据具体的代码感受一下， 逻辑是这样， 首先我们需要写一个数据准备函数， 在这里面就是根据上面的具体步骤准备数据， 得到数据和特征列， 然后就是建立DIN模型并训练， 最后基于模型进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3adde47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入deepctr\n",
    "from deepctr.models import DIN\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import * \n",
    "import tensorflow as tf\n",
    "# tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db1b99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备函数\n",
    "def get_din_feats_columns(df, dense_fea, sparse_fea, behavior_fea, his_behavior_fea, emb_dim=32, max_len=100):\n",
    "    \"\"\"\n",
    "    数据准备函数:\n",
    "    df: 数据集\n",
    "    dense_fea: 数值型特征列\n",
    "    sparse_fea: 离散型特征列\n",
    "    behavior_fea: 用户的候选行为特征列\n",
    "    his_behavior_fea: 用户的历史行为特征列\n",
    "    embedding_dim: embedding的维度， 这里为了简单， 统一把离散型特征列采用一样的隐向量维度\n",
    "    max_len: 用户序列的最大长度\n",
    "    \"\"\"\n",
    "    \n",
    "    sparse_feature_columns = [SparseFeat(feat, vocabulary_size=df[feat].nunique() + 1, embedding_dim=emb_dim) for feat in sparse_fea]\n",
    "    \"我终于理解这个是干什么用的了。。\"\n",
    "    print(sparse_feature_columns)\n",
    "    \n",
    "    dense_feature_columns = [DenseFeat(feat, 1, ) for feat in dense_fea]\n",
    "    print(dense_feature_columns)\n",
    "    \n",
    "    var_feature_columns = [VarLenSparseFeat(SparseFeat(feat, vocabulary_size=df['click_article_id'].nunique() + 1,\n",
    "                                    embedding_dim=emb_dim, embedding_name='click_article_id'), maxlen=max_len) for feat in hist_behavior_fea]\n",
    "    \n",
    "    dnn_feature_columns = sparse_feature_columns + dense_feature_columns + var_feature_columns\n",
    "    \n",
    "    # 建立x, x是一个字典的形式\n",
    "    x = {}\n",
    "    for name in get_feature_names(dnn_feature_columns):\n",
    "        if name in his_behavior_fea:\n",
    "            # 这是历史行为序列\n",
    "            his_list = [l for l in df[name]]\n",
    "            x[name] = pad_sequences(his_list, maxlen=max_len, padding='post')      # 二维数组   # 这里是把他拉长么？\n",
    "        else:\n",
    "            x[name] = df[name].values\n",
    "    \n",
    "    return x, dnn_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78009a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把特征分开\n",
    "\"\"\"\n",
    "这里是根据项目现实情况，主动选择的\n",
    "\"\"\"\n",
    "\n",
    "sparse_fea = ['user_id', 'click_article_id', 'category_id', 'click_environment', 'click_deviceGroup', \n",
    "              'click_os', 'click_country', 'click_region', 'click_referrer_type', 'is_cat_hab']\n",
    "\n",
    "behavior_fea = ['click_article_id']\n",
    "\n",
    "hist_behavior_fea = ['hist_click_article_id']\n",
    "\n",
    "dense_fea = ['sim0', 'time_diff0', 'word_diff0', 'sim_max', 'sim_min', 'sim_sum', 'sim_mean', 'score',\n",
    "             'rank','click_size','time_diff_mean','active_level','user_time_hob1','user_time_hob2',\n",
    "             'words_hbo','words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "280feb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense特征进行归一化, 神经网络训练都需要将数值进行归一化处理\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "# 下面是做一些特殊处理，当在其他的地方出现无效值的时候，不处理无法进行归一化，刚开始可以先把他注释掉，在运行了下面的代码\n",
    "# 之后如果发现报错，应该先去想办法处理如何不出现inf之类的值\n",
    "# trn_user_item_feats_df_din_model.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "# tst_user_item_feats_df_din_model.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "\"\"\"\n",
    "转换 训练，验证，测试 3部分数据\n",
    "\"\"\"\n",
    "for feat in dense_fea:\n",
    "    trn_user_item_feats_df_din_model[feat] = mm.fit_transform(trn_user_item_feats_df_din_model[[feat]])\n",
    "    \n",
    "    if val_user_item_feats_df_din_model is not None:\n",
    "        val_user_item_feats_df_din_model[feat] = mm.fit_transform(val_user_item_feats_df_din_model[[feat]])\n",
    "    \n",
    "    tst_user_item_feats_df_din_model[feat] = mm.fit_transform(tst_user_item_feats_df_din_model[[feat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de9c0859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:142: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:142: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseFeat(name='user_id', vocabulary_size=200001, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027BAEF7B070>, embedding_name='user_id', group_name='default_group', trainable=True), SparseFeat(name='click_article_id', vocabulary_size=7030, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027BAEF65220>, embedding_name='click_article_id', group_name='default_group', trainable=True), SparseFeat(name='category_id', vocabulary_size=195, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027BAEF65DC0>, embedding_name='category_id', group_name='default_group', trainable=True), SparseFeat(name='click_environment', vocabulary_size=4, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027BAEF65C40>, embedding_name='click_environment', group_name='default_group', trainable=True), SparseFeat(name='click_deviceGroup', vocabulary_size=5, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027BAEF65C70>, embedding_name='click_deviceGroup', group_name='default_group', trainable=True), SparseFeat(name='click_os', vocabulary_size=9, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027BAEF65FD0>, embedding_name='click_os', group_name='default_group', trainable=True), SparseFeat(name='click_country', vocabulary_size=12, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027BAEF65F70>, embedding_name='click_country', group_name='default_group', trainable=True), SparseFeat(name='click_region', vocabulary_size=29, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027BAEF651C0>, embedding_name='click_region', group_name='default_group', trainable=True), SparseFeat(name='click_referrer_type', vocabulary_size=8, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027BAEF553A0>, embedding_name='click_referrer_type', group_name='default_group', trainable=True), SparseFeat(name='is_cat_hab', vocabulary_size=2, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027BAEF55970>, embedding_name='is_cat_hab', group_name='default_group', trainable=True)]\n",
      "[DenseFeat(name='sim0', dimension=1, dtype='float32'), DenseFeat(name='time_diff0', dimension=1, dtype='float32'), DenseFeat(name='word_diff0', dimension=1, dtype='float32'), DenseFeat(name='sim_max', dimension=1, dtype='float32'), DenseFeat(name='sim_min', dimension=1, dtype='float32'), DenseFeat(name='sim_sum', dimension=1, dtype='float32'), DenseFeat(name='sim_mean', dimension=1, dtype='float32'), DenseFeat(name='score', dimension=1, dtype='float32'), DenseFeat(name='rank', dimension=1, dtype='float32'), DenseFeat(name='click_size', dimension=1, dtype='float32'), DenseFeat(name='time_diff_mean', dimension=1, dtype='float32'), DenseFeat(name='active_level', dimension=1, dtype='float32'), DenseFeat(name='user_time_hob1', dimension=1, dtype='float32'), DenseFeat(name='user_time_hob2', dimension=1, dtype='float32'), DenseFeat(name='words_hbo', dimension=1, dtype='float32'), DenseFeat(name='words_count', dimension=1, dtype='float32')]\n",
      "[SparseFeat(name='user_id', vocabulary_size=50001, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027B8B3E2AF0>, embedding_name='user_id', group_name='default_group', trainable=True), SparseFeat(name='click_article_id', vocabulary_size=4534, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027B8B3E2910>, embedding_name='click_article_id', group_name='default_group', trainable=True), SparseFeat(name='category_id', vocabulary_size=174, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027B8B3E2CD0>, embedding_name='category_id', group_name='default_group', trainable=True), SparseFeat(name='click_environment', vocabulary_size=4, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027B8B3E2A30>, embedding_name='click_environment', group_name='default_group', trainable=True), SparseFeat(name='click_deviceGroup', vocabulary_size=5, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027B8B3E2D00>, embedding_name='click_deviceGroup', group_name='default_group', trainable=True), SparseFeat(name='click_os', vocabulary_size=9, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027B8B3E2DF0>, embedding_name='click_os', group_name='default_group', trainable=True), SparseFeat(name='click_country', vocabulary_size=12, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027B8B3E2EE0>, embedding_name='click_country', group_name='default_group', trainable=True), SparseFeat(name='click_region', vocabulary_size=29, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027B8B3E9070>, embedding_name='click_region', group_name='default_group', trainable=True), SparseFeat(name='click_referrer_type', vocabulary_size=8, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027B8B3E9100>, embedding_name='click_referrer_type', group_name='default_group', trainable=True), SparseFeat(name='is_cat_hab', vocabulary_size=2, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x0000027B8B3E91F0>, embedding_name='is_cat_hab', group_name='default_group', trainable=True)]\n",
      "[DenseFeat(name='sim0', dimension=1, dtype='float32'), DenseFeat(name='time_diff0', dimension=1, dtype='float32'), DenseFeat(name='word_diff0', dimension=1, dtype='float32'), DenseFeat(name='sim_max', dimension=1, dtype='float32'), DenseFeat(name='sim_min', dimension=1, dtype='float32'), DenseFeat(name='sim_sum', dimension=1, dtype='float32'), DenseFeat(name='sim_mean', dimension=1, dtype='float32'), DenseFeat(name='score', dimension=1, dtype='float32'), DenseFeat(name='rank', dimension=1, dtype='float32'), DenseFeat(name='click_size', dimension=1, dtype='float32'), DenseFeat(name='time_diff_mean', dimension=1, dtype='float32'), DenseFeat(name='active_level', dimension=1, dtype='float32'), DenseFeat(name='user_time_hob1', dimension=1, dtype='float32'), DenseFeat(name='user_time_hob2', dimension=1, dtype='float32'), DenseFeat(name='words_hbo', dimension=1, dtype='float32'), DenseFeat(name='words_count', dimension=1, dtype='float32')]\n"
     ]
    }
   ],
   "source": [
    "# 准备训练数据\n",
    "x_trn, dnn_feature_columns = get_din_feats_columns(trn_user_item_feats_df_din_model, dense_fea, \n",
    "                                               sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "y_trn = trn_user_item_feats_df_din_model['label'].values\n",
    "\n",
    "if offline:\n",
    "    # 准备验证数据\n",
    "    x_val, dnn_feature_columns = get_din_feats_columns(val_user_item_feats_df_din_model, dense_fea, \n",
    "                                                   sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)\n",
    "    y_val = val_user_item_feats_df_din_model['label'].values\n",
    "    \n",
    "dense_fea = [x for x in dense_fea if x != 'label']\n",
    "x_tst, dnn_feature_columns = get_din_feats_columns(tst_user_item_feats_df_din_model, dense_fea, \n",
    "                                               sparse_fea, behavior_fea, hist_behavior_fea, max_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d79ae65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_article_id (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_id (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_environment (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_deviceGroup (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_os (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_country (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_region (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_referrer_type (InputLayer [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "is_cat_hab (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_user_id (Embedding)  (None, 1, 32)        1600032     user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sparse_seq_emb_hist_click_artic multiple             145088      click_article_id[0][0]           \n",
      "                                                                 hist_click_article_id[0][0]      \n",
      "                                                                 click_article_id[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_category_id (Embeddi (None, 1, 32)        5568        category_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_environment (E (None, 1, 32)        128         click_environment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_deviceGroup (E (None, 1, 32)        160         click_deviceGroup[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_os (Embedding) (None, 1, 32)        288         click_os[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_country (Embed (None, 1, 32)        384         click_country[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_region (Embedd (None, 1, 32)        928         click_region[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_click_referrer_type  (None, 1, 32)        256         click_referrer_type[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_is_cat_hab (Embeddin (None, 1, 32)        64          is_cat_hab[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "no_mask (NoMask)                (None, 1, 32)        0           sparse_emb_user_id[0][0]         \n",
      "                                                                 sparse_seq_emb_hist_click_article\n",
      "                                                                 sparse_emb_category_id[0][0]     \n",
      "                                                                 sparse_emb_click_environment[0][0\n",
      "                                                                 sparse_emb_click_deviceGroup[0][0\n",
      "                                                                 sparse_emb_click_os[0][0]        \n",
      "                                                                 sparse_emb_click_country[0][0]   \n",
      "                                                                 sparse_emb_click_region[0][0]    \n",
      "                                                                 sparse_emb_click_referrer_type[0]\n",
      "                                                                 sparse_emb_is_cat_hab[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "hist_click_article_id (InputLay [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 320)       0           no_mask[0][0]                    \n",
      "                                                                 no_mask[1][0]                    \n",
      "                                                                 no_mask[2][0]                    \n",
      "                                                                 no_mask[3][0]                    \n",
      "                                                                 no_mask[4][0]                    \n",
      "                                                                 no_mask[5][0]                    \n",
      "                                                                 no_mask[6][0]                    \n",
      "                                                                 no_mask[7][0]                    \n",
      "                                                                 no_mask[8][0]                    \n",
      "                                                                 no_mask[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_1 (NoMask)              (None, 1, 320)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_sequence_pooling_laye (None, 1, 32)        13961       sparse_seq_emb_hist_click_article\n",
      "                                                                 sparse_seq_emb_hist_click_article\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 352)       0           no_mask_1[0][0]                  \n",
      "                                                                 attention_sequence_pooling_layer[\n",
      "__________________________________________________________________________________________________\n",
      "sim0 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_diff0 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_diff0 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_max (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_min (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_sum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sim_mean (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "score (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rank (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "click_size (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_diff_mean (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "active_level (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_time_hob1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_time_hob2 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "words_hbo (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "words_count (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 352)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_3 (NoMask)              (None, 1)            0           sim0[0][0]                       \n",
      "                                                                 time_diff0[0][0]                 \n",
      "                                                                 word_diff0[0][0]                 \n",
      "                                                                 sim_max[0][0]                    \n",
      "                                                                 sim_min[0][0]                    \n",
      "                                                                 sim_sum[0][0]                    \n",
      "                                                                 sim_mean[0][0]                   \n",
      "                                                                 score[0][0]                      \n",
      "                                                                 rank[0][0]                       \n",
      "                                                                 click_size[0][0]                 \n",
      "                                                                 time_diff_mean[0][0]             \n",
      "                                                                 active_level[0][0]               \n",
      "                                                                 user_time_hob1[0][0]             \n",
      "                                                                 user_time_hob2[0][0]             \n",
      "                                                                 words_hbo[0][0]                  \n",
      "                                                                 words_count[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_2 (NoMask)              (None, 352)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16)           0           no_mask_3[0][0]                  \n",
      "                                                                 no_mask_3[1][0]                  \n",
      "                                                                 no_mask_3[2][0]                  \n",
      "                                                                 no_mask_3[3][0]                  \n",
      "                                                                 no_mask_3[4][0]                  \n",
      "                                                                 no_mask_3[5][0]                  \n",
      "                                                                 no_mask_3[6][0]                  \n",
      "                                                                 no_mask_3[7][0]                  \n",
      "                                                                 no_mask_3[8][0]                  \n",
      "                                                                 no_mask_3[9][0]                  \n",
      "                                                                 no_mask_3[10][0]                 \n",
      "                                                                 no_mask_3[11][0]                 \n",
      "                                                                 no_mask_3[12][0]                 \n",
      "                                                                 no_mask_3[13][0]                 \n",
      "                                                                 no_mask_3[14][0]                 \n",
      "                                                                 no_mask_3[15][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 352)          0           no_mask_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 16)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_4 (NoMask)              multiple             0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 368)          0           no_mask_4[0][0]                  \n",
      "                                                                 no_mask_4[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dnn (DNN)                       (None, 80)           89880       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            80          dnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "prediction_layer (PredictionLay (None, 1)            1           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,856,818\n",
      "Trainable params: 1,856,578\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立模型\n",
    "model = DIN(dnn_feature_columns, behavior_fea)\n",
    "\n",
    "# 查看模型结构\n",
    "model.summary()\n",
    "\n",
    "# 模型编译\n",
    "model.compile('adam', 'binary_crossentropy',metrics=['binary_crossentropy', tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39520cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here...\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[7,0] = 247 is not in [0, 174)\n\t [[node model/sparse_emb_category_id/embedding_lookup (defined at <ipython-input-42-c7915fffe6a3>:8) ]] [Op:__inference_train_function_5140]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/sparse_emb_category_id/embedding_lookup:\n model/sparse_emb_category_id/embedding_lookup/3436 (defined at C:\\ProgramData\\Anaconda3\\lib\\contextlib.py:113)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-c7915fffe6a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# history = model.fit(x_trn, y_trn, verbose=1, epochs=3, validation_split=0.3, batch_size=256)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"here...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[7,0] = 247 is not in [0, 174)\n\t [[node model/sparse_emb_category_id/embedding_lookup (defined at <ipython-input-42-c7915fffe6a3>:8) ]] [Op:__inference_train_function_5140]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/sparse_emb_category_id/embedding_lookup:\n model/sparse_emb_category_id/embedding_lookup/3436 (defined at C:\\ProgramData\\Anaconda3\\lib\\contextlib.py:113)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "if offline:\n",
    "    history = model.fit(x_trn, y_trn, verbose=1, epochs=10, validation_data=(x_val, y_val) , batch_size=256)\n",
    "else:\n",
    "    # 也可以使用上面的语句用自己采样出来的验证集\n",
    "    # history = model.fit(x_trn, y_trn, verbose=1, epochs=3, validation_split=0.3, batch_size=256)\n",
    "    print(\"here...\")\n",
    "    history = model.fit(x_trn, y_trn, verbose=1, epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976879e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b67fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83056cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
